<!DOCTYPE html>
<html lang="en">

<head>
  <meta charset="utf-8" />
   
  <meta name="keywords" content="广外编程社" />
   
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1" />
  <title>
    Python 爬虫（一） |  广外编程社官网
  </title>
  <meta name="generator" content="hexo-theme-yilia-plus">
  
  <link rel="shortcut icon" href="/favicon.ico" />
  
  
<link rel="stylesheet" href="/css/main.css">

  
  <script src="https://cdn.jsdelivr.net/npm/pace-js@1.0.2/pace.min.js"></script>
  
  

  

<link rel="alternate" href="/atom.xml" title="广外编程社官网" type="application/atom+xml">
</head>

</html>

<body>
  <div id="app">
    <main class="content">
      <section class="outer">
  <article id="post-Python-爬虫（一）" class="article article-type-post" itemscope
  itemprop="blogPost" data-scroll-reveal>

  <div class="article-inner">
    
    <header class="article-header">
       
<h1 class="article-title sea-center" style="border-left:0" itemprop="name">
  Python 爬虫（一）
</h1>
  

    </header>
    

    
    <div class="article-meta">
      
        <!-- 不蒜子统计 -->
        <span id="busuanzi_container_page_pv" style='display:none' class="article-date">
              <i class="icon-smile icon"></i> 阅读数：<span id="busuanzi_value_page_pv"></span>次
        </span>


<a href="/2020/06/13/Python-%E7%88%AC%E8%99%AB%EF%BC%88%E4%B8%80%EF%BC%89/" class="article-date">
  <time datetime="2020-06-13T11:58:05.000Z" itemprop="datePublished">2020-06-13</time>
</a>
      
      
      
<div class="word_count">
    <span class="post-time">
        <span class="post-meta-item-icon">
            <i class="ri-quill-pen-line"></i>
            <span class="post-meta-item-text"> 字数统计:</span>
            <span class="post-count">4.2k字</span>
        </span>
    </span>

    <span class="post-time">
        &nbsp; | &nbsp;
        <span class="post-meta-item-icon">
            <i class="ri-book-open-line"></i>
            <span class="post-meta-item-text"> 阅读时长≈</span>
            <span class="post-count">16分钟</span>
        </span>
    </span>
</div>

      
    </div>
    

    
    
    <div class="tocbot"></div>





    

    
    <div class="article-entry" itemprop="articleBody">
      


      

      
      <p> 这是一篇详细介绍 <a href="http://c.biancheng.net/python/" target="_blank" rel="noopener">Python</a> 爬虫入门的教程，从实战出发，适合初学者。读者只需在阅读过程紧跟文章思路，理清相应的实现代码，30 分钟即可学会编写简单的 Python 爬虫。</p>
<p>这篇 Python 爬虫教程主要讲解以下 5 部分内容：</p>
<ol>
<li>了解网页；</li>
<li>使用 requests 库抓取网站数据；</li>
<li>使用 Beautiful Soup 解析网页；</li>
<li>清洗和组织数据；</li>
<li>爬虫攻防战；</li>
</ol>
<h2 id="了解网页"><a href="#了解网页" class="headerlink" title="了解网页"></a>了解网页</h2><p>以中国旅游网首页（<a href="http://www.cntour.cn/）为例，抓取中国旅游网首页首条信息（标题和链接），数据以明文的形式出面在源码中。在中国旅游网首页，按快捷键【Ctrl+U】打开源码页面，如图" target="_blank" rel="noopener">http://www.cntour.cn/）为例，抓取中国旅游网首页首条信息（标题和链接），数据以明文的形式出面在源码中。在中国旅游网首页，按快捷键【Ctrl+U】打开源码页面，如图</a> 1 所示。</p>
<p><img src="http://c.biancheng.net/uploads/allimg/190117/2-1Z11G63943S6.jpg" alt="img"><br>图 1 中国旅游网首页源码</p>
<h3 id="认识网页结构"><a href="#认识网页结构" class="headerlink" title="认识网页结构"></a>认识网页结构</h3><p>网页一般由三部分组成，分别是 HTML（超文本标记语言）、CSS（层叠样式表）和 JScript（活动脚本语言）。</p>
<h4 id="HTML"><a href="#HTML" class="headerlink" title="HTML"></a>HTML</h4><p>HTML 是整个网页的结构，相当于整个网站的框架。带“＜”、“＞”符号的都是属于 HTML 的标签，并且标签都是成对出现的。</p>
<p>常见的标签如下：</p>
<html>..</html> 表示标记中间的元素是网页<body>..</body> 表示用户可见的内容<div>..</div> 表示框架<p>..</p> 表示段落<li>..</li>表示列表<img>..</img>表示图片<h1>..</h1>表示标题<a href="">..</a>表示超链接

<h4 id="CSS"><a href="#CSS" class="headerlink" title="CSS"></a>CSS</h4><p>CSS 表示样式，图 1 中第 13 行＜style type=＂text/css＂＞表示下面引用一个 CSS，在 CSS 中定义了外观。</p>
<h4 id="JScript"><a href="#JScript" class="headerlink" title="JScript"></a>JScript</h4><p>JScript 表示功能。交互的内容和各种特效都在 JScript 中，JScript 描述了网站中的各种功能。</p>
<p>如果用人体来比喻，HTML 是人的骨架，并且定义了人的嘴巴、眼睛、耳朵等要长在哪里。CSS 是人的外观细节，如嘴巴长什么样子，眼睛是双眼皮还是单眼皮，是大眼睛还是小眼睛，皮肤是黑色的还是白色的等。JScript 表示人的技能，例如跳舞、唱歌或者演奏乐器等。</p>
<h3 id="写一个简单的-HTML"><a href="#写一个简单的-HTML" class="headerlink" title="写一个简单的 HTML"></a>写一个简单的 HTML</h3><p>通过编写和修改 HTML，可以更好地理解 HTML。首先打开一个记事本，然后输入下面的内容：</p>
<html><head>    <title> Python 3 爬虫与数据清洗入门与实战</title>
  <meta name="generator" content="hexo-theme-yilia-plus"><link rel="alternate" href="/atom.xml" title="广外编程社官网" type="application/atom+xml">
</head><body>    <div>        <p>Python 3爬虫与数据清洗入门与实战</p>    </div>    <div>        <ul>            <li><a href="http://c.biancheng.net" target="_blank" rel="noopener">爬虫</a></li>            <li>数据清洗</li>        </ul>    </div><script src="/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"log":false,"pluginJsPath":"lib/","pluginModelPath":"assets/","pluginRootPath":"live2dw/","tagMode":false});</script><script src="/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"log":false,"pluginJsPath":"lib/","pluginModelPath":"assets/","pluginRootPath":"live2dw/","tagMode":false});</script><script src="/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"log":false,"pluginJsPath":"lib/","pluginModelPath":"assets/","pluginRootPath":"live2dw/","tagMode":false});</script></body>

<p>输入代码后，保存记事本，然后修改文件名和后缀名为”HTML.html”；</p>
<p>运行该文件后的效果，如图 2 所示。</p>
<p><img src="http://c.biancheng.net/uploads/allimg/190117/2-1Z11G64134V2.gif" alt="img"><br>图 2</p>
<p>这段代码只是用到了 HTML，读者可以自行修改代码中的中文，然后观察其变化。</p>
<h3 id="关于爬虫的合法性"><a href="#关于爬虫的合法性" class="headerlink" title="关于爬虫的合法性"></a>关于爬虫的合法性</h3><p>几乎每一个网站都有一个名为 robots.txt 的文档，当然也有部分网站没有设定 robots.txt。对于没有设定 robots.txt 的网站可以通过网络爬虫获取没有口令加密的数据，也就是该网站所有页面数据都可以爬取。如果网站有 robots.txt 文档，就要判断是否有禁止访客获取的数据。</p>
<p>以淘宝网为例，在浏览器中访问 <a href="https://www.taobao.com/robots.txt，如图" target="_blank" rel="noopener">https://www.taobao.com/robots.txt，如图</a> 3 所示。</p>
<p><img src="http://c.biancheng.net/uploads/allimg/190117/2-1Z11G6422Ub.gif" alt="img"><br>图 3 淘宝网的robots.txt文件内容</p>
<p>淘宝网允许部分爬虫访问它的部分路径，而对于没有得到允许的用户，则全部禁止爬取，代码如下：</p>
<p>User-Agent:*<br>Disallow:/</p>
<p>这一句代码的意思是除前面指定的爬虫外，不允许其他爬虫爬取任何数据。</p>
<h2 id="使用-requests-库请求网站"><a href="#使用-requests-库请求网站" class="headerlink" title="使用 requests 库请求网站"></a>使用 requests 库请求网站</h2><h3 id="安装-requests-库"><a href="#安装-requests-库" class="headerlink" title="安装 requests 库"></a>安装 requests 库</h3><p>首先在 PyCharm 中安装 requests 库，为此打开 PyCharm，单击“File”（文件）菜单，选择“Setting for New Projects…”命令，如图 4 所示。</p>
<p><img src="http://c.biancheng.net/uploads/allimg/190117/2-1Z11G64314Q6.jpg" alt="img"><br>图 4</p>
<p>选择“Project Interpreter”（项目编译器）命令，确认当前选择的编译器，然后单击右上角的加号，如图 5 所示。</p>
<p><img src="http://c.biancheng.net/uploads/allimg/190117/2-1Z11G64341W4.jpg" alt="img"><br>图 5</p>
<p>在搜索框输入：requests（注意，一定要输入完整，不然容易出错），然后单击左下角的“Install Package”（安装库）按钮。如图 6 所示：</p>
<p><img src="http://c.biancheng.net/uploads/allimg/190117/2-1Z11G64400193.jpg" alt="img"><br>图 6</p>
<p>安装完成后，会在 Install Package 上显示“Package‘requests’ installed successfully”（库的请求已成功安装），如图 7 所示；如果安装不成功将会显示提示信息。</p>
<p><img src="http://c.biancheng.net/uploads/allimg/190117/2-1Z11G644192R.jpg" alt="img"><br>图 7 安装成功</p>
<h3 id="爬虫的基本原理"><a href="#爬虫的基本原理" class="headerlink" title="爬虫的基本原理"></a>爬虫的基本原理</h3><p>网页请求的过程分为两个环节：</p>
<ol>
<li>Request （请求）：每一个展示在用户面前的网页都必须经过这一步，也就是向服务器发送访问请求。</li>
<li>Response（响应）：服务器在接收到用户的请求后，会验证请求的有效性，然后向用户（客户端）发送响应的内容，客户端接收服务器响应的内容，将内容展示出来，就是我们所熟悉的网页请求，如图 8 所示。</li>
</ol>
<p><img src="http://c.biancheng.net/uploads/allimg/190117/2-1Z11G6451I08.gif" alt="img"><br>图 8 Response相应</p>
<p>网页请求的方式也分为两种：</p>
<ol>
<li>GET：最常见的方式，一般用于获取或者查询资源信息，也是大多数网站使用的方式，响应速度快。</li>
<li>POST：相比 GET 方式，多了以表单形式上传参数的功能，因此除查询信息外，还可以修改信息。</li>
</ol>
<p>所以，在写爬虫前要先确定向谁发送请求，用什么方式发送。</p>
<h3 id="使用-GET-方式抓取数据"><a href="#使用-GET-方式抓取数据" class="headerlink" title="使用 GET 方式抓取数据"></a>使用 GET 方式抓取数据</h3><p>复制任意一条首页首条新闻的标题，在源码页面按【Ctrl+F】组合键调出搜索框，将标题粘贴在搜索框中，然后按【Enter】键。</p>
<p>如图 8 所示，标题可以在源码中搜索到，请求对象是<a href="http://www.cntour.cn，请求方式是GET（所有在源码中的数据请求方式都是GET），如图" target="_blank" rel="noopener">www.cntour.cn，请求方式是GET（所有在源码中的数据请求方式都是GET），如图</a> 9 所示。</p>
<p><img src="http://c.biancheng.net/uploads/allimg/190117/2-1Z11G64620C9.jpg" alt="img"><br>图 9（<a href="http://c.biancheng.net/uploads/allimg/190117/2-1Z11G6464b94.jpg" target="_blank" rel="noopener">点此查看高清大图</a>）</p>
<p>确定好请求对象和方式后，在 PyCharm 中输入以下代码：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">import requests        #导入requests包url &#x3D; &#39;http:&#x2F;&#x2F;www.cntour.cn&#x2F;&#39;strhtml &#x3D; requests.get(url)        #Get方式获取网页数据print(strhtml.text)</span><br></pre></td></tr></table></figure>

<p>运行结果如图 10 所示：</p>
<p><img src="http://c.biancheng.net/uploads/allimg/190117/2-1Z11G64I4104.jpg" alt="img"><br>图 10 运行结果效果图（<a href="http://c.biancheng.net/uploads/allimg/190117/2-1Z11G64K5445.jpg" target="_blank" rel="noopener">点此查看高清大图</a>）</p>
<p>加载库使用的语句是 import+库的名字。在上述过程中，加载 requests 库的语句是：import requests。</p>
<p>用 GET 方式获取数据需要调用 requests 库中的 get 方法，使用方法是在 requests 后输入英文点号，如下所示：</p>
<p>requests.get</p>
<p>将获取到的数据存到 strhtml 变量中，代码如下：</p>
<p>strhtml = request.get(url)</p>
<p>这个时候 strhtml 是一个 URL 对象，它代表整个网页，但此时只需要网页中的源码，下面的语句表示网页源码：</p>
<p>strhtml.text</p>
<h3 id="使用-POST-方式抓取数据"><a href="#使用-POST-方式抓取数据" class="headerlink" title="使用 POST 方式抓取数据"></a>使用 POST 方式抓取数据</h3><p>首先输入有道翻译的网址：<a href="http://fanyi.youdao.com/，进入有道翻译页面。" target="_blank" rel="noopener">http://fanyi.youdao.com/，进入有道翻译页面。</a></p>
<p>按快捷键 F12，进入开发者模式，单击 Network，此时内容为空，如图 11 所示：</p>
<p><img src="http://c.biancheng.net/uploads/allimg/190117/2-1Z11G64ZU55.gif" alt="img"><br>图 11</p>
<p>在有道翻译中输入“我爱中国”，单击“翻译”按钮，如图 12 所示：</p>
<p><img src="http://c.biancheng.net/uploads/allimg/190117/2-1Z11G6492K96.gif" alt="img"><br>图 12</p>
<p>在开发者模式中，依次单击“Network”按钮和“XHR”按钮，找到翻译数据，如图 13 所示：</p>
<p><img src="http://c.biancheng.net/uploads/allimg/190117/2-1Z11G6494Y00.gif" alt="img"><br>图 13</p>
<p>单击 Headers，发现请求数据的方式为 POST。如图 14 所示：</p>
<p><img src="http://c.biancheng.net/uploads/allimg/190117/2-1Z11GA00I57.gif" alt="img"><br>图 14</p>
<p>找到数据所在之处并且明确请求方式之后，接下来开始撰写爬虫。</p>
<p>首先，将 Headers 中的 URL 复制出来，并赋值给 url，代码如下：</p>
<p>url = ‘<a href="http://fanyi.youdao.com/translate_o?smartresult=dict&amp;smartresult=rule&#39;" target="_blank" rel="noopener">http://fanyi.youdao.com/translate_o?smartresult=dict&amp;smartresult=rule&#39;</a></p>
<p>POST 的请求获取数据的方式不同于 GET，POST 请求数据必须构建请求头才可以。</p>
<p>Form Data 中的请求参数如图 15 所示：</p>
<p><img src="http://c.biancheng.net/uploads/allimg/190117/2-1Z11GA041451.gif" alt="img"><br>图 15</p>
<p>将其复制并构建一个新字典：</p>
<p>From_data={‘i’:’我愛中國’,’from’:’zh-CHS’,’to’:’en’,’smartresult’:’dict’,’client’:’fanyideskweb’,’salt’:’15477056211258’,’sign’:’b3589f32c38bc9e3876a570b8a992604’,’ts’:’1547705621125’,’bv’:’b33a2f3f9d09bde064c9275bcb33d94e’,’doctype’:’json’,’version’:’2.1’,’keyfrom’:’fanyi.web’,’action’:’FY_BY_REALTIME’,’typoResult’:’false’}</p>
<p>接下来使用 requests.post 方法请求表单数据，代码如下：</p>
<p>import requests    #导入requests包<br>response = requests.post(url,data=payload)</p>
<p>将字符串格式的数据转换成 JSON 格式数据，并根据<a href="http://c.biancheng.net/data_structure/" target="_blank" rel="noopener">数据结构</a>，提取数据，并将翻译结果打印出来，代码如下：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">import jsoncontent &#x3D; json.loads(response.text)print(content[&#39;translateResult&#39;][0][0][&#39;tgt&#39;])</span><br></pre></td></tr></table></figure>

<p>使用 requests.post 方法抓取有道翻译结果的完整代码如下：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">import requests        #导入requests包import jsondef get_translate_date(word&#x3D;None):    url &#x3D; &#39;http:&#x2F;&#x2F;fanyi.youdao.com&#x2F;translate_o?smartresult&#x3D;dict&amp;smartresult&#x3D;rule&#39;    From_data&#x3D;&#123;&#39;i&#39;:word,&#39;from&#39;:&#39;zh-CHS&#39;,&#39;to&#39;:&#39;en&#39;,&#39;smartresult&#39;:&#39;dict&#39;,&#39;client&#39;:&#39;fanyideskweb&#39;,&#39;salt&#39;:&#39;15477056211258&#39;,&#39;sign&#39;:&#39;b3589f32c38bc9e3876a570b8a992604&#39;,&#39;ts&#39;:&#39;1547705621125&#39;,&#39;bv&#39;:&#39;b33a2f3f9d09bde064c9275bcb33d94e&#39;,&#39;doctype&#39;:&#39;json&#39;,&#39;version&#39;:&#39;2.1&#39;,&#39;keyfrom&#39;:&#39;fanyi.web&#39;,&#39;action&#39;:&#39;FY_BY_REALTIME&#39;,&#39;typoResult&#39;:&#39;false&#39;&#125;    #请求表单数据    response &#x3D; requests.post(url,data&#x3D;From_data)    #将Json格式字符串转字典    content &#x3D; json.loads(response.text)    print(content)    #打印翻译后的数据    #print(content[&#39;translateResult&#39;][0][0][&#39;tgt&#39;])if __name__&#x3D;&#x3D;&#39;__main__&#39;:    get_translate_date(&#39;我爱中国&#39;)</span><br></pre></td></tr></table></figure>

<h2 id="使用-Beautiful-Soup-解析网页"><a href="#使用-Beautiful-Soup-解析网页" class="headerlink" title="使用 Beautiful Soup 解析网页"></a>使用 Beautiful Soup 解析网页</h2><p>通过 requests 库已经可以抓到网页源码，接下来要从源码中找到并提取数据。Beautiful Soup 是 python 的一个库，其最主要的功能是从网页中抓取数据。Beautiful Soup 目前已经被移植到 bs4 库中，也就是说在导入 Beautiful Soup 时需要先安装 bs4 库。</p>
<p>安装 bs4 库的方式如图 16 所示:</p>
<p><img src="http://c.biancheng.net/uploads/allimg/190117/2-1Z11GA15bD.gif" alt="img"><br>图 16</p>
<p>安装好 bs4 库以后，还需安装 lxml 库。如果我们不安装 lxml 库，就会使用 Python 默认的解析器。尽管 Beautiful Soup 既支持 Python 标准库中的 HTML 解析器又支持一些第三方解析器，但是 lxml 库具有功能更加强大、速度更快的特点，因此笔者推荐安装 lxml 库。</p>
<p>安装 Python 第三方库后，输入下面的代码，即可开启 Beautiful Soup 之旅：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">import requests        #导入requests包from bs4 import    BeautifulSoupurl&#x3D;&#39;http:&#x2F;&#x2F;www.cntour.cn&#x2F;&#39;strhtml&#x3D;requests.get(url)soup&#x3D;BeautifulSoup(strhtml.text,&#39;lxml&#39;)data &#x3D; soup.select(&#39;#main&gt;div&gt;div.mtop.firstMod.clearfix&gt;div.centerBox&gt;ul.newsList&gt;li&gt;a&#39;)print(data)</span><br></pre></td></tr></table></figure>

<p>代码运行结果如图 17 所示。</p>
<p><img src="http://c.biancheng.net/uploads/allimg/190117/2-1Z11GA244Q8.jpg" alt="img"><br>图 17（<a href="http://c.biancheng.net/uploads/allimg/190117/2-1Z11GA30cY.jpg" target="_blank" rel="noopener">点此查看高清大图</a>）</p>
<p>Beautiful Soup 库能够轻松解析网页信息，它被集成在 bs4 库中，需要时可以从 bs4 库中调用。其表达语句如下：</p>
<p>from bs4 import BeautifulSoup</p>
<p>首先，HTML 文档将被转换成 Unicode 编码格式，然后 Beautiful Soup 选择最合适的解析器来解析这段文档，此处指定 lxml 解析器进行解析。解析后便将复杂的 HTML 文档转换成树形结构，并且每个节点都是 Python 对象。这里将解析后的文档存储到新建的变量 soup 中，代码如下：</p>
<p>soup=BeautifulSoup(strhtml.text,’lxml’)</p>
<p>接下来用 select（选择器）定位数据，定位数据时需要使用浏览器的开发者模式，将鼠标光标停留在对应的数据位置并右击，然后在快捷菜单中选择“检查”命令，如图 18 所示：</p>
<p><img src="http://c.biancheng.net/uploads/allimg/190117/2-1Z11GA40T17.gif" alt="img"><br>图 18</p>
<p>随后在浏览器右侧会弹出开发者界面，右侧高亮的代码（参见图 19(b)）对应着左侧高亮的数据文本（参见图 19(a)）。右击右侧高亮数据，在弹出的快捷菜单中选择“Copy”➔“Copy Selector”命令，便可以自动复制路径。</p>
<p><img src="http://c.biancheng.net/uploads/allimg/190117/2-1Z11GA45JN.gif" alt="img"><br>图 19 复制路径</p>
<p>将路径粘贴在文档中，代码如下:</p>
<p>#main &gt; div &gt; div.mtop.firstMod.clearfix &gt; div.centerBox &gt; ul.newsList &gt; li:nth-child(1) &gt; a</p>
<p>由于这条路径是选中的第一条的路径，而我们需要获取所有的头条新闻，因此将 li：nth-child（1）中冒号（包含冒号）后面的部分删掉，代码如下：</p>
<p>#main &gt; div &gt; div.mtop.firstMod.clearfix &gt; div.centerBox &gt; ul.newsList &gt; li &gt; a</p>
<p>使用 soup.select 引用这个路径，代码如下：</p>
<p>data = soup.select(‘#main &gt; div &gt; div.mtop.firstMod.clearfix &gt; div.centerBox &gt; ul.newsList &gt; li &gt; a’)</p>
<h2 id="清洗和组织数据"><a href="#清洗和组织数据" class="headerlink" title="清洗和组织数据"></a>清洗和组织数据</h2><p>至此，获得了一段目标的 HTML 代码，但还没有把数据提取出来，接下来在 PyCharm 中输入以下代码：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">for item in data:    result&#x3D;&#123;        &#39;title&#39;:item.get_text(),        &#39;link&#39;:item.get(&#39;href&#39;)    &#125;print(result)</span><br></pre></td></tr></table></figure>

<p>代码运行结果如图 20 所示：</p>
<p><img src="http://c.biancheng.net/uploads/allimg/190117/2-1Z11GA60R06.gif" alt="img"><br>图 20（<a href="http://c.biancheng.net/uploads/allimg/190117/2-1Z11GA629403.jpg" target="_blank" rel="noopener">点此查看高清大图</a>）</p>
<p>首先明确要提取的数据是标题和链接，标题在＜a＞标签中，提取标签的正文用 get_text() 方法。链接在＜a＞标签的 href 属性中，提取标签中的 href 属性用 get() 方法，在括号中指定要提取的属性数据，即 get(＇href＇)。</p>
<p>从图 20 中可以发现，文章的链接中有一个数字 ID。下面用正则表达式提取这个 ID。需要使用的正则符号如下:</p>
<p>\d匹配数字<br>+匹配前一个字符1次或多次</p>
<p>在 Python 中调用正则表达式时使用 re 库，这个库不用安装，可以直接调用。在 PyCharm 中输入以下代码:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">import refor item in data:    result&#x3D;&#123;        &quot;title&quot;:item.get_text(),        &quot;link&quot;:item.get(&#39;href&#39;),        &#39;ID&#39;:re.findall(&#39;\d+&#39;,item.get(&#39;href&#39;))    &#125;print(result)</span><br></pre></td></tr></table></figure>

<p>运行结果如图 21 所示：</p>
<p><img src="http://c.biancheng.net/uploads/allimg/190117/2-1Z11GAHKD.jpg" alt="img"><br>图 21</p>
<p>这里使用 re 库的 findall 方法，第一个参数表示正则表达式，第二个参数表示要提取的文本。</p>
<h2 id="爬虫攻防战"><a href="#爬虫攻防战" class="headerlink" title="爬虫攻防战"></a>爬虫攻防战</h2><p>爬虫是模拟人的浏览访问行为，进行数据的批量抓取。当抓取的数据量逐渐增大时，会给被访问的服务器造成很大的压力，甚至有可能崩溃。换句话就是说，服务器是不喜欢有人抓取自己的数据的。那么，网站方面就会针对这些爬虫者，采取一些反爬策略。</p>
<p>服务器第一种识别爬虫的方式就是通过检查连接的 useragent 来识别到底是浏览器访问，还是代码访问的。如果是代码访问的话，访问量增大时，服务器会直接封掉来访 IP。</p>
<p>那么应对这种初级的反爬机制，我们应该采取何种举措？</p>
<p>还是以前面创建好的爬虫为例。在进行访问时，我们在开发者环境下不仅可以找到 URL、Form Data，还可以在 Request headers 中构造浏览器的请求头，封装自己。服务器识别浏览器访问的方法就是判断 keyword 是否为 Request headers 下的 User-Agent，如图 22 所示。</p>
<p><img src="http://c.biancheng.net/uploads/allimg/190117/2-1Z11GAR3P1.jpg" alt="img"><br>图 22</p>
<p>因此，我们只需要构造这个请求头的参数。创建请求头部信息即可，代码如下：</p>
<p>headers={‘User-Agent’:’Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/70.0.3538.110 Safari/537.36’}<br>response = request.get(url,headers=headers)</p>
<p>写到这里，很多读者会认为修改 User-Agent 很太简单。确实很简单，但是正常人1秒看一个图，而个爬虫1秒可以抓取好多张图，比如 1 秒抓取上百张图，那么服务器的压力必然会增大。也就是说，如果在一个 IP 下批量访问下载图片，这个行为不符合正常人类的行为，肯定要被封 IP。</p>
<p>其原理也很简单，就是统计每个IP的访问频率，该频率超过阈值，就会返回一个验证码，如果真的是用户访问的话，用户就会填写，然后继续访问，如果是代码访问的话，就会被封 IP。</p>
<p>这个问题的解决方案有两个，第一个就是常用的增设延时，每 3 秒钟抓取一次，代码如下：</p>
<p>import time<br>time.sleep(3)</p>
<p>但是，我们写爬虫的目的是为了高效批量抓取数据，这里设置 3 秒钟抓取一次，效率未免太低。其实，还有一个更重要的解决办法，那就是从本质上解决问题。</p>
<p>不管如何访问，服务器的目的就是查出哪些为代码访问，然后封锁 IP。解决办法：为避免被封 IP，在数据采集时经常会使用代理。当然，requests 也有相应的 proxies 属性。</p>
<p>首先，构建自己的代理 IP 池，将其以字典的形式赋值给 proxies，然后传输给 requests，代码如下：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">proxies&#x3D;&#123;    &quot;http&quot;:&quot;http:&#x2F;&#x2F;10.10.1.10:3128&quot;,    &quot;https&quot;:&quot;http:&#x2F;&#x2F;10.10.1.10:1080&quot;,&#125;response &#x3D; requests.get(url, proxies&#x3D;proxies)</span><br></pre></td></tr></table></figure>

<h2 id="扩展阅读"><a href="#扩展阅读" class="headerlink" title="扩展阅读"></a>扩展阅读</h2><p>本文仅对 Python 爬虫及实现过程做了简明扼要地介绍，仅能使初学者对 python 爬虫有一个浅显的认识，并不能让你完全掌握 Python 爬虫。</p>
<p>如果你想对 Python 爬虫有更深入的了解，我推荐你阅读：</p>
<ul>
<li><a href="https://www.cnblogs.com/Albert-Lee/p/6226699.html" target="_blank" rel="noopener">Python爬虫入门教程 </a></li>
<li><a href="https://blog.csdn.net/c406495762/article/details/78123502" target="_blank" rel="noopener">Python3网络爬虫入门教程</a></li>
<li><a href="http://www.imooc.com/learn/563" target="_blank" rel="noopener">Python爬虫教程——慕课网</a></li>
</ul>

      
      <!-- reward -->
      
    </div>
    
    
      <!-- copyright -->
      
    <footer class="article-footer">
      
          
<div class="share-btn">
      <span class="share-sns share-outer">
        <i class="ri-share-forward-line"></i>
        分享
      </span>
      <div class="share-wrap">
        <i class="arrow"></i>
        <div class="share-icons">
          
          <a class="weibo share-sns" href="javascript:;" data-type="weibo">
            <i class="ri-weibo-fill"></i>
          </a>
          <a class="weixin share-sns wxFab" href="javascript:;" data-type="weixin">
            <i class="ri-wechat-fill"></i>
          </a>
          <a class="qq share-sns" href="javascript:;" data-type="qq">
            <i class="ri-qq-fill"></i>
          </a>
          <a class="douban share-sns" href="javascript:;" data-type="douban">
            <i class="ri-douban-line"></i>
          </a>
          <!-- <a class="qzone share-sns" href="javascript:;" data-type="qzone">
            <i class="icon icon-qzone"></i>
          </a> -->
          
          <a class="facebook share-sns" href="javascript:;" data-type="facebook">
            <i class="ri-facebook-circle-fill"></i>
          </a>
          <a class="twitter share-sns" href="javascript:;" data-type="twitter">
            <i class="ri-twitter-fill"></i>
          </a>
          <a class="google share-sns" href="javascript:;" data-type="google">
            <i class="ri-google-fill"></i>
          </a>
        </div>
      </div>
</div>

<div class="wx-share-modal">
    <a class="modal-close" href="javascript:;"><i class="ri-close-circle-line"></i></a>
    <p>扫一扫，分享到微信</p>
    <div class="wx-qrcode">
      <img src="//api.qrserver.com/v1/create-qr-code/?size=150x150&data=http://yoursite.com/2020/06/13/Python-%E7%88%AC%E8%99%AB%EF%BC%88%E4%B8%80%EF%BC%89/" alt="微信分享二维码">
    </div>
</div>

<div id="share-mask"></div>
      
      
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/python/" rel="tag">python</a></li></ul>


    </footer>

  </div>

  
  
  <nav class="article-nav">
    
      <a href="/2020/06/13/Python-%E7%88%AC%E8%99%AB%EF%BC%88%E4%BA%8C%EF%BC%89/" class="article-nav-link">
        <strong class="article-nav-caption">上一篇</strong>
        <div class="article-nav-title">
          
            Python 爬虫（二）
          
        </div>
      </a>
    
    
      <a href="/2020/06/13/Python-pip/" class="article-nav-link">
        <strong class="article-nav-caption">下一篇</strong>
        <div class="article-nav-title">Python pip</div>
      </a>
    
  </nav>


  

  
  
<!-- valine评论 -->
<div id="vcomments-box">
    <div id="vcomments">
    </div>
</div>
<script src="//cdn1.lncld.net/static/js/3.0.4/av-min.js"></script>
<script src='https://cdn.jsdelivr.net/npm/valine@1.3.10/dist/Valine.min.js'></script>
<script>
    new Valine({
        el: '#vcomments',
        app_id: '9KjOP8UIrxMNeout6rbPNABM-gzGzoHsz',
        app_key: 'p8jYOMTugImVVUXFa52wB63J',
        path: window.location.pathname,
        notify: 'true',
        verify: 'true',
        avatar: 'mp',
        placeholder: '给我的文章加点评论吧~',
        recordIP: true
    });
    const infoEle = document.querySelector('#vcomments .info');
    if (infoEle && infoEle.childNodes && infoEle.childNodes.length > 0) {
        infoEle.childNodes.forEach(function (item) {
            item.parentNode.removeChild(item);
        });
    }
</script>
<style>
    #vcomments-box {
        padding: 5px 30px;
    }

    @media screen and (max-width: 800px) {
        #vcomments-box {
            padding: 5px 0px;
        }
    }

    #vcomments-box #vcomments {
        background-color: #fff;
    }

    .v .vlist .vcard .vh {
        padding-right: 20px;
    }

    .v .vlist .vcard {
        padding-left: 10px;
    }
</style>

  

  
  
  

</article>
</section>


      <footer class="footer">
  <div class="outer">
    <ul class="list-inline">
      <li>
        &copy;
        2020
        广外编程社
      </li>
      <li>
      </li>
    </ul>
    <ul class="list-inline">
      <li>
        
        
        <span>
  <i>PV:<span id="busuanzi_value_page_pv"></span></i>
  <i>UV:<span id="busuanzi_value_site_uv"></span></i>
</span>
        
      </li>
      
      <li>
        <!-- cnzz统计 -->
        
        <script type="text/javascript" src='https://v1.cnzz.com/z_stat.php?id=1278929797&amp;web_id=1278929797'></script>
        
      </li>
    </ul>
  </div>


        <!-- 不蒜子统计 -->
        <span id="busuanzi_container_site_pv">
                本站总访问量<span id="busuanzi_value_site_pv"></span>次
        </span>
        <span class="post-meta-divider">|</span>
        <span id="busuanzi_container_site_uv" style='display:none'>
                本站访客数<span id="busuanzi_value_site_uv"></span>人
        </span>
        <script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>
  

</footer>

<span id="timeDate">载入天数...</span><span id="times">载入时分秒...</span>
<script>
    var now = new Date(); 
    function createtime() { 
        var grt= new Date("08/4/2020 17:38:00");//在此处修改你的建站时间，格式：月/日/年 时:分:秒
        now.setTime(now.getTime()+250); 
        days = (now - grt ) / 1000 / 60 / 60 / 24; dnum = Math.floor(days); 
        hours = (now - grt ) / 1000 / 60 / 60 - (24 * dnum); hnum = Math.floor(hours); 
        if(String(hnum).length ==1 ){hnum = "0" + hnum;} minutes = (now - grt ) / 1000 /60 - (24 * 60 * dnum) - (60 * hnum); 
        mnum = Math.floor(minutes); if(String(mnum).length ==1 ){mnum = "0" + mnum;} 
        seconds = (now - grt ) / 1000 - (24 * 60 * 60 * dnum) - (60 * 60 * hnum) - (60 * mnum); 
        snum = Math.round(seconds); if(String(snum).length ==1 ){snum = "0" + snum;} 
        document.getElementById("timeDate").innerHTML = "本站已安全运行 "+dnum+" 天 "; 
        document.getElementById("times").innerHTML = hnum + " 小时 " + mnum + " 分 " + snum + " 秒"; 
    } 
setInterval("createtime()",250);
</script>
      <div class="to_top">
        <div class="totop" id="totop">
  <i class="ri-arrow-up-line"></i>
</div>
      </div>
    </main>
    <aside class="sidebar">
      <button class="navbar-toggle"></button>
<nav class="navbar">
  
  <div class="logo">
    <a href="/"><img src="/images/logo.png" alt="广外编程社官网"></a>
  </div>
  
  <ul class="nav nav-main">
    
    <li class="nav-item">
      <a class="nav-item-link" href="/">主页</a>
    </li>
    
    <li class="nav-item">
      <a class="nav-item-link" href="/archives">归档</a>
    </li>
    
    <li class="nav-item">
      <a class="nav-item-link" href="/categories">分类</a>
    </li>
    
    <li class="nav-item">
      <a class="nav-item-link" href="/tags">标签</a>
    </li>
    
    <li class="nav-item">
      <a class="nav-item-link" href="https://gw-lazybones.github.io/2020/05/30/%EF%BC%88%E7%BD%AE%E9%A1%B6%EF%BC%89GZFLS%20LazyBones%20%E7%AE%80%E4%BB%8B" target="_blank" rel="noopener">关于我</a>
    </li>
    
  </ul>
</nav>
<nav class="navbar navbar-bottom">
  <ul class="nav">
    <li class="nav-item">
      
      <a class="nav-item-link nav-item-search"  title="Search">
        <i class="ri-search-line"></i>
      </a>
      
      
      <a class="nav-item-link" target="_blank" href="/atom.xml" title="RSS Feed">
        <i class="ri-rss-line"></i>
      </a>
      
    </li>
  </ul>
</nav>
<div class="search-form-wrap">
  <div class="local-search local-search-plugin">
  <input type="search" id="local-search-input" class="local-search-input" placeholder="Search...">
  <div id="local-search-result" class="local-search-result"></div>
</div>
</div>
    </aside>
    <div id="mask"></div>

<!-- #reward -->
<div id="reward">
  <span class="close"><i class="ri-close-line"></i></span>
  <p class="reward-p"><i class="ri-cup-line"></i>就当交个团费吧~</p>
  <div class="reward-box">
    
    <div class="reward-item">
      <img class="reward-img" src="/images/alipay.jpg">
      <span class="reward-type">支付宝</span>
    </div>
    
    
    <div class="reward-item">
      <img class="reward-img" src="/images/wechat.jpg">
      <span class="reward-type">微信</span>
    </div>
    
  </div>
</div>
    
<script src="/js/jquery-2.0.3.min.js"></script>


<script src="/js/share.js"></script>


<script src="/js/lazyload.min.js"></script>


<script>
  try {
    var typed = new Typed("#subtitle", {
      strings: ['广外编程社官网', '提供Python，C++；hexo等资料', '提供Python，C++；hexo等资料'],
      startDelay: 0,
      typeSpeed: 200,
      loop: true,
      backSpeed: 100,
      showCursor: true
    });
  } catch (err) {
  }

</script>




<script src="/js/tocbot.min.js"></script>

<script>
  // Tocbot_v4.7.0  http://tscanlin.github.io/tocbot/
  tocbot.init({
    tocSelector: '.tocbot',
    contentSelector: '.article-entry',
    headingSelector: 'h1, h2, h3, h4, h5, h6',
    hasInnerContainers: true,
    scrollSmooth: true,
    scrollContainer: 'main',
    positionFixedSelector: '.tocbot',
    positionFixedClass: 'is-position-fixed',
    fixedSidebarOffset: 'auto',
    onClick: (e) => {
      $('.toc-link').removeClass('is-active-link');
      $(`a[href=${e.target.hash}]`).addClass('is-active-link');
      $(e.target.hash).scrollIntoView();
      return false;
    }
  });
</script>



<script src="https://cdn.jsdelivr.net/npm/jquery-modal@0.9.2/jquery.modal.min.js"></script>
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/jquery-modal@0.9.2/jquery.modal.min.css">
<script src="https://cdn.jsdelivr.net/npm/justifiedGallery@3.7.0/dist/js/jquery.justifiedGallery.min.js"></script>

<script src="/js/ayer.js"></script>



<!-- Root element of PhotoSwipe. Must have class pswp. -->
<div class="pswp" tabindex="-1" role="dialog" aria-hidden="true">

    <!-- Background of PhotoSwipe. 
         It's a separate element as animating opacity is faster than rgba(). -->
    <div class="pswp__bg"></div>

    <!-- Slides wrapper with overflow:hidden. -->
    <div class="pswp__scroll-wrap">

        <!-- Container that holds slides. 
            PhotoSwipe keeps only 3 of them in the DOM to save memory.
            Don't modify these 3 pswp__item elements, data is added later on. -->
        <div class="pswp__container">
            <div class="pswp__item"></div>
            <div class="pswp__item"></div>
            <div class="pswp__item"></div>
        </div>

        <!-- Default (PhotoSwipeUI_Default) interface on top of sliding area. Can be changed. -->
        <div class="pswp__ui pswp__ui--hidden">

            <div class="pswp__top-bar">

                <!--  Controls are self-explanatory. Order can be changed. -->

                <div class="pswp__counter"></div>

                <button class="pswp__button pswp__button--close" title="Close (Esc)"></button>

                <button class="pswp__button pswp__button--share" style="display:none" title="Share"></button>

                <button class="pswp__button pswp__button--fs" title="Toggle fullscreen"></button>

                <button class="pswp__button pswp__button--zoom" title="Zoom in/out"></button>

                <!-- Preloader demo http://codepen.io/dimsemenov/pen/yyBWoR -->
                <!-- element will get class pswp__preloader--active when preloader is running -->
                <div class="pswp__preloader">
                    <div class="pswp__preloader__icn">
                        <div class="pswp__preloader__cut">
                            <div class="pswp__preloader__donut"></div>
                        </div>
                    </div>
                </div>
            </div>

            <div class="pswp__share-modal pswp__share-modal--hidden pswp__single-tap">
                <div class="pswp__share-tooltip"></div>
            </div>

            <button class="pswp__button pswp__button--arrow--left" title="Previous (arrow left)">
            </button>

            <button class="pswp__button pswp__button--arrow--right" title="Next (arrow right)">
            </button>

            <div class="pswp__caption">
                <div class="pswp__caption__center"></div>
            </div>

        </div>

    </div>

</div>

<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe.min.css">
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/default-skin/default-skin.css">
<script src="https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe-ui-default.min.js"></script>

<script>
    function viewer_init() {
        let pswpElement = document.querySelectorAll('.pswp')[0];
        let $imgArr = document.querySelectorAll(('.article-entry img:not(.reward-img)'))

        $imgArr.forEach(($em, i) => {
            $em.onclick = () => {
                // slider展开状态
                // todo: 这样不好，后面改成状态
                if (document.querySelector('.left-col.show')) return
                let items = []
                $imgArr.forEach(($em2, i2) => {
                    let img = $em2.getAttribute('data-idx', i2)
                    let src = $em2.getAttribute('data-target') || $em2.getAttribute('src')
                    let title = $em2.getAttribute('alt')
                    // 获得原图尺寸
                    const image = new Image()
                    image.src = src
                    items.push({
                        src: src,
                        w: image.width || $em2.width,
                        h: image.height || $em2.height,
                        title: title
                    })
                })
                var gallery = new PhotoSwipe(pswpElement, PhotoSwipeUI_Default, items, {
                    index: parseInt(i)
                });
                gallery.init()
            }
        })
    }
    viewer_init()
</script>


<script type="text/x-mathjax-config">
  MathJax.Hub.Config({
      tex2jax: {
          inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
          processEscapes: true,
          skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
      }
  });

  MathJax.Hub.Queue(function() {
      var all = MathJax.Hub.getAllJax(), i;
      for(i=0; i < all.length; i += 1) {
          all[i].SourceElement().parentNode.className += ' has-jax';
      }
  });
</script>

<script src="https://cdn.jsdelivr.net/npm/mathjax@2.7.6/unpacked/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
<script>
  var ayerConfig = {
    mathjax: true
  }
</script>



<script src="/js/busuanzi-2.3.pure.min.js"></script>



<script type="text/javascript" src="https://js.users.51.la/20544303.js"></script>


<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@3.5.2/dist/jquery.fancybox.min.css">
<script src="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@3.5.2/dist/jquery.fancybox.min.js"></script>


    
  </div>
<script src="/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"log":false,"pluginJsPath":"lib/","pluginModelPath":"assets/","pluginRootPath":"live2dw/","tagMode":false});</script></body>

</html>

<!--单击显示文字-->
<script type="text/javascript" src="/js/click_show_text.js"></script>

<canvas class="fireworks" style="position: fixed;left: 0;top: 0;z-index: 1; pointer-events: none;" ></canvas> 
<script type="text/javascript" src="//cdn.bootcss.com/animejs/2.2.0/anime.min.js"></script> 
<script type="text/javascript" src="/js/fireworks.js"></script>

<!--浏览器搞笑标题-->
<script type="text/javascript" src="/js/FunnyTitle.js"></script>

<!--动态线条背景-->
<script type="text/javascript"
color="220,220,220" opacity='1.4' zIndex="-4" count="182" src="//cdn.bootcss.com/canvas-nest.js/1.0.0/canvas-nest.min.js">
</script>
